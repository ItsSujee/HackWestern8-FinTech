{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "!pip install flask_ngrok\n",
    "from flask_ngrok import run_with_ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8de85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 23:50:21.284040: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load Trained ML Model\n",
    "model = keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178bde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\")\n",
    "sentences = []\n",
    "with open(\"dataset/spam_dataset.csv\", encoding=\"ISO-8859-1\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        sentences.append(row[1])\n",
    "split = int(len(sentences)*0.85)\n",
    "training_x = sentences[:split]\n",
    "tokenizer.fit_on_texts(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d5de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 1286, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
      "    ngrok_address = _run_ngrok()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/flask_ngrok.py\", line 31, in _run_ngrok\n",
      "    ngrok = subprocess.Popen([executable, 'http', '5000'])\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 1821, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "PermissionError: [Errno 13] Permission denied: '/var/folders/cc/4hjry6592tb8bjn26czrm34c0000gn/T/ngrok/ngrok'\n",
      "127.0.0.1 - - [20/Nov/2021 23:54:08] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:54:08] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:54:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:55:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:55:38] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:55:41] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2021 23:55:46] \"\u001b[33mGET /query/test HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "# Production ML API \n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "@app.route(\"/query/\", methods = ['POST'])\n",
    "def query():\n",
    "    content = request.form.get(\"query\")\n",
    "    content = content[0:189]\n",
    "    padded = pad_sequences(tokenizer.texts_to_sequences([content]), maxlen=189)\n",
    "    prediction = model.predict(padded)\n",
    "    confidence = prediction[0][0] * 100\n",
    "    if confidence < 0.03:\n",
    "        answer = \"real\"\n",
    "    else:\n",
    "        answer = \"fake\"\n",
    "    return { \"prediction\": answer, \"confidence\": confidence}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba8226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
